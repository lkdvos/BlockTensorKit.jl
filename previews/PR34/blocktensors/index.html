<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>BlockTensors · BlockTensorKit.jl</title><meta name="title" content="BlockTensors · BlockTensorKit.jl"/><meta property="og:title" content="BlockTensors · BlockTensorKit.jl"/><meta property="twitter:title" content="BlockTensors · BlockTensorKit.jl"/><meta name="description" content="Documentation for BlockTensorKit.jl."/><meta property="og:description" content="Documentation for BlockTensorKit.jl."/><meta property="twitter:description" content="Documentation for BlockTensorKit.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="BlockTensorKit.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">BlockTensorKit.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../sumspaces/">SumSpace</a></li><li class="is-active"><a class="tocitem" href>BlockTensors</a><ul class="internal"><li><a class="tocitem" href="#AbstractBlockTensorMap"><span><code>AbstractBlockTensorMap</code></span></a></li></ul></li></ul></li><li><a class="tocitem" href="../lib/">Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>BlockTensors</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>BlockTensors</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/lkdvos/BlockTensorKit.jl.git" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="github.com/lkdvos/BlockTensorKit.jl.git" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="AbstractBlockTensorMap"><a class="docs-heading-anchor" href="#AbstractBlockTensorMap"><code>AbstractBlockTensorMap</code></a><a id="AbstractBlockTensorMap-1"></a><a class="docs-heading-anchor-permalink" href="#AbstractBlockTensorMap" title="Permalink"></a></h2><p>The main type of this package is <code>BlockTensorMap</code>, which is a generalization of <code>AbstractTensorMap</code> to the case where the tensor is a concatenation of other tensors. The design philosophy is to have the same interface as <code>AbstractTensorMap</code>, with the additional ability to query the individual tensors that make up the block tensor, as <code>AbstractArray{AbstractTensorMap}</code>.</p><h3 id="Type-hierarchy"><a class="docs-heading-anchor" href="#Type-hierarchy">Type hierarchy</a><a id="Type-hierarchy-1"></a><a class="docs-heading-anchor-permalink" href="#Type-hierarchy" title="Permalink"></a></h3><p>The type hierarchy of the <code>AbstractBlockTensorMap</code> consists of one abstract and two concrete subtypes of <code>AbstractBlockTensorMap</code>:</p><pre><code class="language-julia hljs">BlockTensorMap &lt;: AbstractBlockTensorMap &lt;: AbstractTensorMap
SparseBlockTensorMap &lt;: AbstractBlockTensorMap &lt;: AbstractTensorMap</code></pre><p>In particular, these structures hold the structural information as a <code>HomSpace</code> of <code>SumSpace</code>s, as defined in <a href="@ref"><code>SumSpaces</code></a>, as well as the individual tensors that make up the block tensor. For <code>BlockTensorMap</code>, the list of tensors is dense, thus they are stored in an <code>Array{AbstractTensorMap,N}</code>, where <code>N</code> is the total number of indices of a tensor. For <code>SparseBlockTensorMap</code>, this is not the case, and the list of tensors is stored in a <code>Dict{CartesianIndex{N},AbstractTensorMap}</code>.</p><p>The elementary constructors for these types are:</p><pre><code class="language-julia hljs">BlockTensorMap{TT}(undef, space::TensorMapSumSpace)
SparseBlockTensorMap{TT}(undef, space::TensorMapSumSpace)</code></pre><p>where <code>TT&lt;:AbstractTensorMap</code> is the type of the individual tensors, and <code>space</code> is the <code>TensorMapSumSpace</code> that defines the structure of the block tensor.</p><div class="admonition is-info" id="Note-d7dbd9bd1874dd83"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-d7dbd9bd1874dd83" title="Permalink"></a></header><div class="admonition-body"><p>In rare cases, <code>undef_blocks</code> can also be used, which won&#39;t allocate the component tensors. In these cases it is left up to the user to not access elements before they are allocated.</p></div></div><p>Similarly, they can be initialized from a list of tensors:</p><pre><code class="language-julia hljs">BlockTensorMap{TT}(tensors::AbstractArray{AbstractTensorMap,N}, space::TensorMapSumSpace)
SparseBlockTensorMap{TT}(tensors::Dict{CartesianIndex{N},AbstractTensorMap}, space::TensorMapSumSpace)</code></pre><p>Typically though, the most convenient way of obtaining a block tensor is by using one of <code>zeros</code>, <code>rand</code> or <code>randn</code>, as well as their sparse counterparts <code>spzeros</code> or <code>sprand</code>.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using TensorKit, BlockTensorKit</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; using BlockTensorKit: ⊕</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; V = ℂ^1 ⊕ ℂ^2;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; W = V * V → V;</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t = rand(W)</code><code class="nohighlight hljs ansi" style="display:block;">TensorMap(ℂ^3 ← (ℂ^3 ⊗ ℂ^3)):
[:, :, 1] =
 0.1856674541227601    0.46933520799514206  0.6109073748764917
 0.7758767499357692    0.3933799665098564   0.49564434014654646
 0.008648913436195338  0.5931474055075145   0.27150892445634556

[:, :, 2] =
 0.8576130511085852  0.017457013697160906  0.4354429159247759
 0.9712341115522954  0.024804251803690947  0.6212082743618037
 0.8950951153249359  0.4107113002833598    0.5852395634051296

[:, :, 3] =
 0.730483964764584    0.7393067926930441  0.14784506714593637
 0.04369743892450939  0.6018686562635033  0.9713564110687404
 0.8002429914602119   0.0466238241784146  0.4490020234905223</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; eltype(t)</code><code class="nohighlight hljs ansi" style="display:block;">Float64</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; s = sprand(W, 0.5)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: MethodError: no method matching sprand(::TensorKit.TensorMapSpace{TensorKit.ComplexSpace, 1, 2}, ::Float64)
The function `sprand` exists, but no method is defined for this combination of argument types.

Closest candidates are:
  sprand(<span class="sgr91">::TensorKit.HomSpace{SumSpace{S}, TensorKit.ProductSpace{SumSpace{S}, N₁}, TensorKit.ProductSpace{SumSpace{S}, N₂}} where {S, N₁, N₂}</span>, ::Real)
<span class="sgr90">   @</span> <span class="sgr35">BlockTensorKit</span> <span class="sgr90">~/work/BlockTensorKit.jl/BlockTensorKit.jl/src/tensors/<span class="sgr4">sparseblocktensor.jl:126</span></span>
  sprand(<span class="sgr91">::Union{SumSpace{S}, TensorKit.ProductSpace{SumSpace{S}}} where S</span>, ::Real)
<span class="sgr90">   @</span> <span class="sgr35">BlockTensorKit</span> <span class="sgr90">~/work/BlockTensorKit.jl/BlockTensorKit.jl/src/tensors/<span class="sgr4">sparseblocktensor.jl:129</span></span>
  sprand(<span class="sgr91">::Type</span>, <span class="sgr91">::Union{SumSpace{S}, TensorKit.ProductSpace{SumSpace{S}}} where S</span>, <span class="sgr91">::Union{SumSpace{S}, TensorKit.ProductSpace{SumSpace{S}}} where S</span>, <span class="sgr91">::Real</span>)
<span class="sgr90">   @</span> <span class="sgr35">BlockTensorKit</span> <span class="sgr90">~/work/BlockTensorKit.jl/BlockTensorKit.jl/src/tensors/<span class="sgr4">sparseblocktensor.jl:137</span></span>
  ...</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; eltype(s)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: `s` not defined in `Main`
Suggestion: check for spelling errors or missing imports.</code></pre><div class="admonition is-info" id="Note-bdcfcfb5c9bb8772"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-bdcfcfb5c9bb8772" title="Permalink"></a></header><div class="admonition-body"><p>In analogy to <code>TensorKit</code>, most of the functionality that requires a <code>space</code> object can equally well be called in terms of <code>codomain(space), domain(space)</code>, if that is more convenient.</p></div></div><h3 id="Indexing"><a class="docs-heading-anchor" href="#Indexing">Indexing</a><a id="Indexing-1"></a><a class="docs-heading-anchor-permalink" href="#Indexing" title="Permalink"></a></h3><p>For indexing operators, <code>AbstractBlockTensorMap</code> behaves like an <code>AbstractArray{AbstractTensorMap}</code>, and the individual tensors can be accessed via the <code>getindex</code> and <code>setindex!</code> functions. In particular, the <code>getindex</code> function returns a <code>TT</code> object, and the <code>setindex!</code> function expects a <code>TT</code> object. Both linear and cartesian indexing styles are supported.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; t[1] isa eltype(t)</code><code class="nohighlight hljs ansi" style="display:block;">true</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t[1] == t[1, 1, 1]</code><code class="nohighlight hljs ansi" style="display:block;">true</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t[2] = 3 * t[2]</code><code class="nohighlight hljs ansi" style="display:block;">2.3276302498073074</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; s[1] isa eltype(t)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: `s` not defined in `Main`
Suggestion: check for spelling errors or missing imports.</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; s[1] == s[1, 1, 1]</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: `s` not defined in `Main`
Suggestion: check for spelling errors or missing imports.</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; s[1] += 2 * s[1]</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: `s` not defined in `Main`
Suggestion: check for spelling errors or missing imports.</code></pre><p>Slicing operations are also supported, and the <code>AbstractBlockTensorMap</code> can be sliced in the same way as an <code>AbstractArray{AbstractTensorMap}</code>. There is however one elementary difference: as the slices still contain tensors with the same amount of legs, there can be no reduction in the number of dimensions. In particular, in contrast to <code>AbstractArray</code>, scalar dimensions are not discarded, and as a result, linear index slicing is not allowed.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; ndims(t[1, 1, :]) == 3</code><code class="nohighlight hljs ansi" style="display:block;">false</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; ndims(t[:, 1:2, [1, 1]]) == 3</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: MethodError: no method matching getindex(::TensorKit.TensorMap{Float64, TensorKit.ComplexSpace, 1, 2, Vector{Float64}}, ::Colon, ::UnitRange{Int64}, ::Vector{Int64})
The function `getindex` exists, but no method is defined for this combination of argument types.

Closest candidates are:
  getindex(::TensorKit.AbstractTensorMap, <span class="sgr91">::Union{Colon, AbstractRange{&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8}}, Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8}...</span>)
<span class="sgr90">   @</span> <span class="sgr36">TensorKit</span> <span class="sgr90">~/.julia/packages/TensorKit/gu4dl/src/tensors/<span class="sgr4">abstracttensor.jl:313</span></span>
  getindex(::TensorKit.AbstractTensorMap)
<span class="sgr90">   @</span> <span class="sgr36">TensorKit</span> <span class="sgr90">~/.julia/packages/TensorKit/gu4dl/src/tensors/<span class="sgr4">abstracttensor.jl:341</span></span>
  getindex(::TensorKit.TensorMap{T, S, N₁, N₂, A} where A&lt;:DenseVector{T}, <span class="sgr91">::TensorKit.FusionTree{TensorKitSectors.Trivial, N₁}</span>, <span class="sgr91">::TensorKit.FusionTree{TensorKitSectors.Trivial, N₂}</span>) where {T, S, N₁, N₂}
<span class="sgr90">   @</span> <span class="sgr36">TensorKit</span> <span class="sgr90">~/.julia/packages/TensorKit/gu4dl/src/tensors/<span class="sgr4">tensor.jl:499</span></span>
  ...</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t[1:2] # error</code><code class="nohighlight hljs ansi" style="display:block;">2-element StridedViews.StridedView{Float64, 1, Memory{Float64}, typeof(identity)}:
 0.1856674541227601
 2.3276302498073074</code></pre><h3 id="VectorInterface.jl"><a class="docs-heading-anchor" href="#VectorInterface.jl">VectorInterface.jl</a><a id="VectorInterface.jl-1"></a><a class="docs-heading-anchor-permalink" href="#VectorInterface.jl" title="Permalink"></a></h3><p>As part of the <code>TensorKit</code> interface, <code>AbstractBlockTensorMap</code> also implements <code>VectorInterface</code>. This means that you can efficiently add, scale, and compute the inner product of <code>AbstractBlockTensorMap</code> objects.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; t1, t2 = rand!(similar(t)), rand!(similar(t));</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; add(t1, t2, rand())</code><code class="nohighlight hljs ansi" style="display:block;">TensorMap(ℂ^3 ← (ℂ^3 ⊗ ℂ^3)):
[:, :, 1] =
 0.4437627144105405  1.0778143816724701  0.5901873181363005
 0.9176847543576591  0.2901656053574636  0.6691794987505456
 0.8012778418771624  0.440626962710529   0.5639913672613179

[:, :, 2] =
 0.6441672317778097  0.5381192964745403  0.9930349799162946
 1.0292682385489589  0.7260546919893338  0.6126095089276822
 0.7100502176392254  1.052200724830711   0.23283525324882204

[:, :, 3] =
 1.2753619133827967  0.3062755332647279   1.0217021330155676
 0.5573550498241957  0.4205314509775565   0.5781555433914976
 1.0795402499326432  0.37952311400369515  1.0760485714533832</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; scale(t1, rand())</code><code class="nohighlight hljs ansi" style="display:block;">TensorMap(ℂ^3 ← (ℂ^3 ⊗ ℂ^3)):
[:, :, 1] =
 0.022085650333738327  0.1017376830280777    0.05636943969780632
 0.1002063668544657    0.010679796991352731  0.04532550321984906
 0.07004129043073783   0.047241312285210814  0.02957856367507912

[:, :, 2] =
 0.048335914883314235  0.02670549513238055  0.0979964608180769
 0.08758393627917951   0.06830726206518548  0.04364530175083112
 0.04885027592333603   0.08908433950681262  0.0046345828657077615

[:, :, 3] =
 0.11512388337448187  0.027892349389294135  0.09522185059119827
 0.04111117101265099  0.012781923338327358  0.038554232198376406
 0.09823385147916684  0.013174866440466481  0.0873429316696322</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; inner(t1, t2)</code><code class="nohighlight hljs ansi" style="display:block;">8.599204970859866</code></pre><p>For further in-place and possibly-in-place methods, see <a href="https://github.com/Jutho/VectorInterface.jl"><code>VectorInterface.jl</code></a></p><h3 id="TensorOperations.jl"><a class="docs-heading-anchor" href="#TensorOperations.jl">TensorOperations.jl</a><a id="TensorOperations.jl-1"></a><a class="docs-heading-anchor-permalink" href="#TensorOperations.jl" title="Permalink"></a></h3><p>The <code>TensorOperations.jl</code> interface is also implemented for <code>AbstractBlockTensorMap</code>. In particular, the <code>AbstractBlockTensorMap</code> can be contracted with other <code>AbstractBlockTensorMap</code> objects, as well as with <code>AbstractTensorMap</code> objects. In order for that mix to work, the <code>AbstractTensorMap</code> objects are automatically converted to <code>AbstractBlockTensorMap</code> objects with a single tensor, i.e. the sum spaces will be a sum of one space. As a consequence, as soon as one of the input tensors is blocked, the output tensor will also be blocked, even though its size might be trivial. In these cases, <code>only</code> can be used to retrieve the single element in the <code>BlockTensorMap</code>.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; @tensor t3[a; b] := t[a; c d] * conj(t[b; c d])</code><code class="nohighlight hljs ansi" style="display:block;">TensorMap(ℂ^3 ← ℂ^3):
 2.655410707830476   2.6439579521698477  2.1609277720589204
 2.6439579521698477  8.455772983159855   2.1302965773840743
 2.1609277720589204  2.1302965773840743  2.582165572117792</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; @tensor t4[a; b] := t[1, :, :][a; c d] * conj(t[1, :, :][b; c d]) # blocktensor * blocktensor = blocktensor</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: TensorOperations.IndexError{String}(&quot;invalid permutation of length 2: ((1,), (2, 3))&quot;)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t4 isa AbstractBlockTensorMap</code><code class="nohighlight hljs ansi" style="display:block;">false</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; only(t4) isa eltype(t4)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: ArgumentError: Collection has multiple elements, must contain exactly 1 element</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; @tensor t5[a; b] := t[1][a; c d] * conj(t[1:1, 1:1, 1:1][b; c d]) # tensor * blocktensor = blocktensor</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: MethodError: no method matching tensorcontract_type(::Type{Float64}, ::Float64, ::Tuple{Tuple{Int64}, Tuple{Int64, Int64}}, ::Bool, ::StridedViews.StridedView{Float64, 3, Memory{Float64}, typeof(identity)}, ::Tuple{Tuple{Int64, Int64}, Tuple{Int64}}, ::Bool, ::Tuple{Tuple{Int64}, Tuple{Int64}})
The function `tensorcontract_type` exists, but no method is defined for this combination of argument types.

Closest candidates are:
  tensorcontract_type(::Any, <span class="sgr91">::AbstractArray</span>, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}} where {N₁, N₂}, ::Bool, ::AbstractArray, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}} where {N₁, N₂}, ::Bool, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}} where {N₁, N₂})
<span class="sgr90">   @</span> <span class="sgr32">TensorOperations</span> <span class="sgr90">~/.julia/packages/TensorOperations/35umh/src/implementation/<span class="sgr4">allocator.jl:136</span></span>
  tensorcontract_type(::Any, <span class="sgr91">::AbstractBlockTensorMap</span>, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}} where {N₁, N₂}, ::Bool, <span class="sgr91">::AbstractBlockTensorMap</span>, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}} where {N₁, N₂}, ::Bool, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}}) where {N₁, N₂}
<span class="sgr90">   @</span> <span class="sgr35">BlockTensorKit</span> <span class="sgr90">~/work/BlockTensorKit.jl/BlockTensorKit.jl/src/tensors/<span class="sgr4">tensoroperations.jl:36</span></span>
  tensorcontract_type(::Any, <span class="sgr91">::TensorKit.AbstractTensorMap</span>, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}} where {N₁, N₂}, ::Bool, <span class="sgr91">::AbstractBlockTensorMap</span>, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}} where {N₁, N₂}, ::Bool, ::Tuple{NTuple{N₁, Int64}, NTuple{N₂, Int64}}) where {N₁, N₂}
<span class="sgr90">   @</span> <span class="sgr35">BlockTensorKit</span> <span class="sgr90">~/work/BlockTensorKit.jl/BlockTensorKit.jl/src/tensors/<span class="sgr4">tensoroperations.jl:54</span></span>
  ...</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t5 isa AbstractBlockTensorMap</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: `t5` not defined in `Main`
Suggestion: check for spelling errors or missing imports.</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; only(t5) isa eltype(t5)</code><code class="nohighlight hljs ansi" style="display:block;">ERROR: UndefVarError: `t5` not defined in `Main`
Suggestion: check for spelling errors or missing imports.</code></pre><h3 id="Factorizations"><a class="docs-heading-anchor" href="#Factorizations">Factorizations</a><a id="Factorizations-1"></a><a class="docs-heading-anchor-permalink" href="#Factorizations" title="Permalink"></a></h3><p>Currently, there is only rudimentary support for factorizations of <code>AbstractBlockTensorMap</code> objects. In particular, the implementations are not yet optimized for performance, and the factorizations are typically carried out by mapping to a dense tensor, and then performing the factorization on that tensor.</p><div class="admonition is-info" id="Note-cee81a2efd8ffb70"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-cee81a2efd8ffb70" title="Permalink"></a></header><div class="admonition-body"><p>Most factorizations do not retain the additional imposed block structure. In particular, constructions of orthogonal bases will typically mix up the subspaces, and as such the resulting vector spaces will be <code>SumSpace</code>s of a single term.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../sumspaces/">« SumSpace</a><a class="docs-footer-nextpage" href="../lib/">Library »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 7 October 2025 23:43">Tuesday 7 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
