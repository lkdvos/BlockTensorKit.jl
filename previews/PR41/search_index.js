var documenterSearchIndex = {"docs":
[{"location":"blocktensors/#AbstractBlockTensorMap","page":"BlockTensors","title":"AbstractBlockTensorMap","text":"The main type of this package is BlockTensorMap, which is a generalization of AbstractTensorMap to the case where the tensor is a concatenation of other tensors. The design philosophy is to have the same interface as AbstractTensorMap, with the additional ability to query the individual tensors that make up the block tensor, as AbstractArray{AbstractTensorMap}.","category":"section"},{"location":"blocktensors/#Type-hierarchy","page":"BlockTensors","title":"Type hierarchy","text":"The type hierarchy of the AbstractBlockTensorMap consists of one abstract and two concrete subtypes of AbstractBlockTensorMap:\n\nBlockTensorMap <: AbstractBlockTensorMap <: AbstractTensorMap\nSparseBlockTensorMap <: AbstractBlockTensorMap <: AbstractTensorMap\n\nIn particular, these structures hold the structural information as a HomSpace of SumSpaces, as defined in SumSpaces, as well as the individual tensors that make up the block tensor. For BlockTensorMap, the list of tensors is dense, thus they are stored in an Array{AbstractTensorMap,N}, where N is the total number of indices of a tensor. For SparseBlockTensorMap, this is not the case, and the list of tensors is stored in a Dict{CartesianIndex{N},AbstractTensorMap}.\n\nThe elementary constructors for these types are:\n\nBlockTensorMap{TT}(undef, space::TensorMapSumSpace)\nSparseBlockTensorMap{TT}(undef, space::TensorMapSumSpace)\n\nwhere TT<:AbstractTensorMap is the type of the individual tensors, and space is the TensorMapSumSpace that defines the structure of the block tensor.\n\nnote: Note\nIn rare cases, undef_blocks can also be used, which won't allocate the component tensors. In these cases it is left up to the user to not access elements before they are allocated.\n\nSimilarly, they can be initialized from a list of tensors:\n\nBlockTensorMap{TT}(tensors::AbstractArray{AbstractTensorMap,N}, space::TensorMapSumSpace)\nSparseBlockTensorMap{TT}(tensors::Dict{CartesianIndex{N},AbstractTensorMap}, space::TensorMapSumSpace)\n\nTypically though, the most convenient way of obtaining a block tensor is by using one of zeros, rand or randn, as well as their sparse counterparts spzeros or sprand.\n\nusing TensorKit, BlockTensorKit\nV = ℂ^1 ⊞ ℂ^2;\nW = V * V → V;\nt = rand(W)\neltype(t)\ns = sprand(W, 0.5)\neltype(s)\n\nnote: Note\nIn analogy to TensorKit, most of the functionality that requires a space object can equally well be called in terms of codomain(space), domain(space), if that is more convenient.","category":"section"},{"location":"blocktensors/#Indexing","page":"BlockTensors","title":"Indexing","text":"For indexing operators, AbstractBlockTensorMap behaves like an AbstractArray{AbstractTensorMap}, and the individual tensors can be accessed via the getindex and setindex! functions. In particular, the getindex function returns a TT object, and the setindex! function expects a TT object. Both linear and cartesian indexing styles are supported.\n\nt[1] isa eltype(t)\nt[1] == t[1, 1, 1]\nt[2] = 3 * t[2]\ns[1] isa eltype(t)\ns[1] == s[1, 1, 1]\ns[1] += 2 * s[1]\n\nSlicing operations are also supported, and the AbstractBlockTensorMap can be sliced in the same way as an AbstractArray{AbstractTensorMap}. There is however one elementary difference: as the slices still contain tensors with the same amount of legs, there can be no reduction in the number of dimensions. In particular, in contrast to AbstractArray, scalar dimensions are not discarded, and as a result, linear index slicing is not allowed.\n\nndims(t[1, 1, :]) == 3\nndims(t[:, 1:2, [1, 1]]) == 3\nt[1:2] # error","category":"section"},{"location":"blocktensors/#VectorInterface.jl","page":"BlockTensors","title":"VectorInterface.jl","text":"As part of the TensorKit interface, AbstractBlockTensorMap also implements VectorInterface. This means that you can efficiently add, scale, and compute the inner product of AbstractBlockTensorMap objects.\n\nt1, t2 = rand!(similar(t)), rand!(similar(t));\nadd(t1, t2, rand())\nscale(t1, rand())\ninner(t1, t2)\n\nFor further in-place and possibly-in-place methods, see VectorInterface.jl","category":"section"},{"location":"blocktensors/#TensorOperations.jl","page":"BlockTensors","title":"TensorOperations.jl","text":"The TensorOperations.jl interface is also implemented for AbstractBlockTensorMap. In particular, the AbstractBlockTensorMap can be contracted with other AbstractBlockTensorMap objects, as well as with AbstractTensorMap objects. In order for that mix to work, the AbstractTensorMap objects are automatically converted to AbstractBlockTensorMap objects with a single tensor, i.e. the sum spaces will be a sum of one space. As a consequence, as soon as one of the input tensors is blocked, the output tensor will also be blocked, even though its size might be trivial. In these cases, only can be used to retrieve the single element in the BlockTensorMap.\n\n@tensor t3[a; b] := t[a; c d] * conj(t[b; c d])\n@tensor t4[a; b] := t[1, :, :][a; c d] * conj(t[1, :, :][b; c d]) # blocktensor * blocktensor = blocktensor\nt4 isa AbstractBlockTensorMap\nonly(t4) isa eltype(t4)\n@tensor t5[a; b] := t[1][a; c d] * conj(t[1:1, 1:1, 1:1][b; c d]) # tensor * blocktensor = blocktensor\nt5 isa AbstractBlockTensorMap\nonly(t5) isa eltype(t5)","category":"section"},{"location":"blocktensors/#Factorizations","page":"BlockTensors","title":"Factorizations","text":"Currently, there is only rudimentary support for factorizations of AbstractBlockTensorMap objects. In particular, the implementations are not yet optimized for performance, and the factorizations are typically carried out by mapping to a dense tensor, and then performing the factorization on that tensor.\n\nnote: Note\nMost factorizations do not retain the additional imposed block structure. In particular, constructions of orthogonal bases will typically mix up the subspaces, and as such the resulting vector spaces will be SumSpaces of a single term.","category":"section"},{"location":"lib/#Library-index","page":"Library","title":"Library index","text":"","category":"section"},{"location":"lib/#BlockTensorKit.AbstractBlockTensorMap","page":"Library","title":"BlockTensorKit.AbstractBlockTensorMap","text":"AbstractBlockTensorMap{E,S,N₁,N₂}\n\nAbstract supertype for tensor maps that have additional block structure, i.e. they act on vector spaces that have a direct sum structure. These behave like AbstractTensorMap but have additional methods to facilitate indexing and manipulation of the block structure.\n\n\n\n\n\n","category":"type"},{"location":"lib/#BlockTensorKit.BlockTensorMap","page":"Library","title":"BlockTensorKit.BlockTensorMap","text":"struct BlockTensorMap{TT<:AbstractTensorMap{E,S,N₁,N₂}} <: AbstractTensorMap{E,S,N₁,N₂}\n\nDense BlockTensorMap type that stores tensors of type TT in a dense array.\n\n\n\n\n\n","category":"type"},{"location":"lib/#BlockTensorKit.SparseBlockTensorMap","page":"Library","title":"BlockTensorKit.SparseBlockTensorMap","text":"struct SparseBlockTensorMap{TT<:AbstractTensorMap{E,S,N₁,N₂}} <: AbstractBlockTensorMap{E,S,N₁,N₂}\n\nSparse SparseBlockTensorMap type that stores tensors of type TT in a sparse dictionary.\n\n\n\n\n\n","category":"type"},{"location":"lib/#BlockTensorKit.SumSpace","page":"Library","title":"BlockTensorKit.SumSpace","text":"struct SumSpace{S<:ElementarySpace} <: ElementarySpace\n\nA (lazy) direct sum of elementary vector spaces of type S.\n\n\n\n\n\n","category":"type"},{"location":"lib/#BlockTensorKit.SumSpaceIndices","page":"Library","title":"BlockTensorKit.SumSpaceIndices","text":"struct SumSpaceIndices{S,N₁,N₂} <: AbstractArray{TensorMapSpace{S,N₁,N₂},N₁ + N₂}\n\n\n\n\n\n","category":"type"},{"location":"lib/#BlockTensorKit.:⊞","page":"Library","title":"BlockTensorKit.:⊞","text":"V1 ⊞ V2...\nboxplus(V1::ElementarySpace, V2::ElementarySpace...)\n\nCreate a lazy representation of the direct sum of the supplied vector spaces, which retains the order. See also SumSpace.\n\n\n\n\n\n","category":"function"},{"location":"lib/#BlockTensorKit.droptol!","page":"Library","title":"BlockTensorKit.droptol!","text":"droptol!(t::AbstractBlockTensorMap, tol=eps(real(scalartype(t)))^(3/4))\n\nRemove the tensor entries of a blocktensor that have norm ≤(tol).\n\n\n\n\n\n","category":"function"},{"location":"lib/#BlockTensorKit.dropzeros!-Tuple{AbstractBlockTensorMap}","page":"Library","title":"BlockTensorKit.dropzeros!","text":"dropzeros!(t::AbstractBlockTensorMap)\n\nRemove the tensor entries of a blocktensor that have norm 0. Only applicable to sparse blocktensors.\n\n\n\n\n\n","category":"method"},{"location":"lib/#BlockTensorKit.eachspace-Tuple{TensorKit.HomSpace{SumSpace{S}, TensorKit.ProductSpace{SumSpace{S}, N₁}, TensorKit.ProductSpace{SumSpace{S}, N₂}} where {S, N₁, N₂}}","page":"Library","title":"BlockTensorKit.eachspace","text":"eachspace(V::TensorMapSumSpace) -> SumSpaceIndices\n\nReturn an object that can be used to obtain the subspaces of a BlockTensorMap.\n\n\n\n\n\n","category":"method"},{"location":"lib/#BlockTensorKit.sprand-Tuple{TensorKit.HomSpace{SumSpace{S}, TensorKit.ProductSpace{SumSpace{S}, N₁}, TensorKit.ProductSpace{SumSpace{S}, N₂}} where {S, N₁, N₂}, Real}","page":"Library","title":"BlockTensorKit.sprand","text":"sprand([rng], T::Type, W::TensorMapSumSpace, p::Real)\n\nConstruct a sparse blocktensor with entries compatible with type T and space W. Each entry is nonzero with probability p.\n\n\n\n\n\n","category":"method"},{"location":"lib/#BlockTensorKit.spzeros-Tuple{TensorKit.HomSpace{SumSpace{S}, TensorKit.ProductSpace{SumSpace{S}, N₁}, TensorKit.ProductSpace{SumSpace{S}, N₂}} where {S, N₁, N₂}, Vararg{Any}}","page":"Library","title":"BlockTensorKit.spzeros","text":"spzeros(T::Type, W::TensorMapSumSpace)\nspzeros(T, W, nonzero_inds)\n\nConstruct a sparse blocktensor with entries compatible with type T and space W. By default, the tensor will be empty, but nonzero entries can be specified by passing a tuple of indices nonzero_inds.\n\n\n\n\n\n","category":"method"},{"location":"lib/#BlockTensorKit.sumspacetype-Union{Tuple{Type{S}}, Tuple{S}} where S<:TensorKit.ElementarySpace","page":"Library","title":"BlockTensorKit.sumspacetype","text":"sumspacetype(::Union{S,Type{S}}) where {S<:ElementarySpace}\n\nReturn the type of a SumSpace with elements of type S.\n\n\n\n\n\n","category":"method"},{"location":"sumspaces/#sec_sumspaces","page":"SumSpace","title":"Direct Sum Spaces","text":"The underlying concept that defines any array (or operator) that has some blocked structure is that of a direct sum of vector spaces. These spaces are a natural extension of the TensorKit vector spaces, and you can think of them as a way to lazily concatenate multiple vector spaces into one.","category":"section"},{"location":"sumspaces/#SumSpace","page":"SumSpace","title":"SumSpace","text":"In BlockTensorKit, we provide a type SumSpace that allows you to define such direct sums. They can be defined either directly via the constructor, or by using the ⊞ (\\boxplus<TAB>) operator. In order for the direct sum to be wll-defined, all components must have the same value of isdual.\n\nEssentially, that is all there is to it, and you can now use these SumSpace objects much in the same way as you would use an IndexSpace object in TensorKit. In particular, it adheres to the interface of ElementarySpace, which means that you can query the properties as you would expect.\n\nnote: Note\nThe notion of a direct sum of vector spaces is used in both TensorKit (⊕ or oplus) and BlockTensorKit (⊞ or boxplus). Both functions achieve almost the same thing, and BlockTensorKit.⊞ can be thought of as a lazy version of TensorKit.⊕.\n\nusing TensorKit, BlockTensorKit\nV = ℂ^1 ⊞ ℂ^2 ⊞ ℂ^3\nℂ^2 ⊞ (ℂ^2)' ⊞ ℂ^2 # error\ndim(V)\nisdual(V)\nisdual(V')\nfield(V)\nspacetype(V)\nInnerProductStyle(V)\n\nThe main difference is that the object retains the information about the individual spaces, and you can query them by indexing into the object.\n\nlength(V)\nV[1]","category":"section"},{"location":"sumspaces/#ProductSumSpace-and-TensorMapSumSpace","page":"SumSpace","title":"ProductSumSpace and TensorMapSumSpace","text":"Because these objects are naturally ElementarySpace objects, they can be used in the construction of ProductSpace and HomSpace objects, and in particular, they can be used to define the spaces of TensorMap objects. Additionally, when mixing spaces and their sumspaces, all components are promoted to SumSpace instances.\n\nV1 = ℂ^1 ⊞ ℂ^2 ⊞ ℂ^3\nV2 = ℂ^2\nV1 ⊗ V2 ⊗ V1' == V1 * V2 * V1' == ProductSpace(V1,V2,V1') == ProductSpace(V1,V2) ⊗ V1'\nV1^3\ndim(V1 ⊗ V2)\ndims(V1 ⊗ V2)\ndual(V1 ⊗ V2)\nspacetype(V1 ⊗ V2)\nspacetype(typeof(V1 ⊗ V2))\n\nW = V1 → V2\nfield(W)\ndual(W)\nadjoint(W)\nspacetype(W)\nspacetype(typeof(W))\nW[1]\nW[2]\ndim(W)","category":"section"},{"location":"sumspaces/#SumSpaceIndices","page":"SumSpace","title":"SumSpaceIndices","text":"Finally, since the SumSpace object is the underlying structure of a blocked tensor, it can be convenient to have a way to obtain the vector spaces of the constituent parts. For this, we provide the SumSpaceIndices object, which can be used to efficiently iterate over the indices of the individual spaces. In particular, we expose the eachspace function, similar to eachindex, to obtain such an iterator.\n\nW = V1 * V2 → V2 * V1\neachspace(W)","category":"section"},{"location":"#BlockTensorKit.jl","page":"Home","title":"BlockTensorKit.jl","text":"A Julia package for handling arrays-of-tensors, built on top of TensorKit.jl","category":"section"},{"location":"#Package-summary","page":"Home","title":"Package summary","text":"In the context of developing efficient tensor network algorithms, it can sometimes be convenient to write a tensor as a concatenation of other tensors, without explicitly merging them. This is helpful whenever there are some guarantees on the resulting structure, such as sparsity patterns, triangular structures, or just as a way of keeping things organized. One particular example, for which this package is primarily developed, is the construction of Matrix Product Operators (MPOs) that represent a sum of local operators, both on 1-dimensional geometries, but also for more general tree-like geometries. In those cases, the combination of an upper-triangular blocked structure, as well as efficient usage of the sparsity, can not only greatly speed up runtime, but also facilitates rapid development of novel algorithms.\n\nMathematically speaking, we can consider these blocked tensors as acting on direct sums of vector spaces, where the indiviual vector spaces are supplied by TensorKit. This leads to a very natural generalization of AbstractTensorMap, which is able to handle arbitrary symmetries.\n\nBlockTensorKit.jl aims to provide a convenient interface to such blocked tensors. In particular, the central types of this package (<:AbstractBlockTensorMap) could be describes as having both AbstractArray-like interfaces, which allow indexing as well as slicing operations, and AbstractTensorMap-like interfaces, allowing linear algebra routines, tensor contraction and tensor factorization. The goal is to abstract away the need to deal with the inner structures of such tensors as much as possible, and have the ability to replace AbstractTensorMaps with AbstractBlockTensorMap without having to change the high-level code.\n\nAs these kinds of operations typically appear in performance-critical sections of the code, computational efficiency and performance are high on the priority list. As such, a secondary aim of this package is to provide different algorithms that enable maximal usage of sparsity, multithreading, and other tricks to obtain close-to-maximal performance.","category":"section"},{"location":"#Contents-of-the-manual","page":"Home","title":"Contents of the manual","text":"The manual fort his package is separated into 4 large parts. The first part focusses on the spacetype that underlies these tensors, which contain the necessary information to construct them. This is followed by a section on BlockTensorMap, highlighting the capabilities and interface. Then, we elaborate on SparseBlockTensorMap, which contains the sparse variant. Finally, we collect all docstrings.\n\nPages = [\"sumspaces.md\", \"blocktensor.md\", \"sparseblocktensor.md\", \"lib.md\"]","category":"section"}]
}
